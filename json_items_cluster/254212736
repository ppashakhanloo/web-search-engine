{"id": 254212736, "abstract": "Dirichlet process (DP) mixture models are the cornerstone of nonparametric Bayesian\nstatistics, and the development of Monte-Carlo Markov chain (MCMC) sampling methods for DP\nmixtures has enabled the application of nonparametric Bayesian methods to a variety of\npractical data analysis problems. However, MCMC sampling can be prohibitively slow, and it\nis important to explore alternatives. One class of alternatives is provided by variational\nmethods, a class of deterministic algorithms that convert inference problems into\noptimization problems (Opper and Saad 2001; Wainwright and Jordan 2003). Thus far,\nvariational methods have mainly been explored in the parametric setting, in particular\nwithin the formalism of the exponential family (Attias 2000; Ghahramani and Beal 2001;\nBlei et al. 2003). In this paper, we present a variational inference algorithm for DP\nmixtures. We present experiments that compare the algorithm to Gibbs sampling algorithms\nfor DP mixtures of Gaussians and present an application to a large-scale image analysis \nproblem.", "cluster": "5", "citations": [266261649, 283117782, 266735007, 270906298, 260985227, 267454297, 267099477, 265383462, 262266576, 269630292], "references": [221620547, 2480258, 2491892, 2495015], "authors": ["David M. Blei", "Michael I. Jordan"], "title": "Variational inference for Dirichlet process mixtures. Bayesian Anal 1:121-144"}