{"id": 259478458, "abstract": "The paper proposes a novel upper confidence bound (UCB) procedure for\nidentifying the arm with the largest mean in a multi-armed bandit game in the\nfixed confidence setting using a small number of total samples. The procedure\ncannot be improved in the sense that the number of samples required to identify\nthe best arm is within a constant factor of a lower bound based on the law of\nthe iterated logarithm (LIL). Inspired by the LIL, we construct our confidence\nbounds to explicitly account for the infinite time horizon of the algorithm. In\naddition, by using a novel stopping time for the algorithm we avoid a union\nbound over the arms that has been observed in other UCB-type algorithms. We\nprove that the algorithm is optimal up to constants and also show through\nsimulations that it provides superior performance with respect to the\nstate-of-the-art.", "cluster": "0", "citations": [279633530, 275669988, 265967035, 263545276, 242014552, 281854812, 280104102, 280590277], "references": [238951707, 221394179, 38365999, 264948136, 235709950, 268291396, 221497401], "authors": ["Kevin Jamieson", "Matthew Malloy", "Robert Nowak", "SÃ©bastien Bubeck"], "title": "lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits"}