{"id": 228095688, "abstract": "Multitask learning algorithms are typically designed assuming some fixed, a\npriori known latent structure shared by all the tasks. However, it is usually\nunclear what type of latent task structure is the most appropriate for a given\nmultitask learning problem. Ideally, the \"right\" latent task structure should\nbe learned in a data-driven manner. We present a flexible, nonparametric\nBayesian model that posits a mixture of factor analyzers structure on the\ntasks. The nonparametric aspect makes the model expressive enough to subsume\nmany existing models of latent task structures (e.g, mean-regularized tasks,\nclustered tasks, low-rank or linear/non-linear subspace assumption on tasks,\netc.). Moreover, it can also learn more general task structures, addressing the\nshortcomings of such models. We present a variational inference algorithm for\nour model. Experimental results on synthetic and real-world datasets, on both\nregression and classification problems, demonstrate the effectiveness of the\nproposed method.", "cluster": "0", "citations": [273770572, 269997485, 234083373, 290818928, 288203703], "references": [220699313, 2239690, 220320877, 221344864, 254212736, 220319924, 27290603, 220325787, 222819870, 221618095], "authors": ["Alexandre Passos", "Piyush Rai", "Jacques Wainer", "Hal Daume III"], "title": "Flexible Modeling of Latent Task Structures in Multitask Learning"}