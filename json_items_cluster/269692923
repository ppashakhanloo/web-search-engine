{"id": 269692923, "abstract": "Dynamics-based sampling methods, such as Hybrid Monte Carlo (HMC) and Langevin dynamics (LD), are commonly used to sample target distributions. Re-cently, such approaches have been combined with stochastic gradient techniques to increase sampling efficiency when dealing with large datasets. An outstanding problem with this approach is that the stochastic gradient introduces an unknown amount of noise which can prevent proper sampling after discretization. To rem-edy this problem, we show that one can leverage a small number of additional variables to stabilize momentum fluctuations induced by the unknown noise. Our method is inspired by the idea of a thermostat in statistical physics and is justified by a general theory.", "cluster": "4", "citations": [288713780, 288059869, 288059688, 278413644, 278413473, 275974197, 273157486, 270454388, 268748346, 272844713], "references": [228095582, 236235190, 262157385, 260232379, 262192443, 227375782, 228092206, 29522811, 221941068, 256117605], "authors": ["Nan Ding", "Youhan Fang", "Ryan Babbush", "Changyou Chen", "Robert D Skeel", "Hartmut Neven"], "title": "Bayesian Sampling Using Stochastic Gradient Thermostats"}