{"id": 49628576, "abstract": "In a clinical setting, pain is reported either through patient self-report or via an observer. Such measures are problematic as they are: 1) subjective, and 2) give no specific timing information. Coding pain as a series of facial action units (AUs) can avoid these issues as it can be used to gain an objective measure of pain on a frame-by-frame basis. Using video data from patients with shoulder injuries, in this paper, we describe an active appearance model (AAM)-based system that can automatically detect the frames in video in which a patient is in pain. This pain data set highlights the many challenges associated with spontaneous emotion detection, particularly that of expression and head movement due to the patient's reaction to pain. In this paper, we show that the AAM can deal with these movements and can achieve significant improvements in both the AU and pain detection performance compared to the current-state-of-the-art approaches which utilize similarity-normalized appearance features only.", "cluster": "2", "citations": [278743074, 254257855, 267719949, 225282372, 261387182, 221292544, 258713575, 259990631, 261319404, 257093268], "references": [225940935, 221292140, 4082379, 221052632, 260662411, 222679587, 230574153, 3845529, 5348301, 3193260], "authors": ["Patrick Lucey", "Jeffrey F Cohn", "Iain Matthews", "Simon Lucey", "Sridha Sridharan", "Jessica Howlett", "Kenneth M Prkachin"], "title": "Automatically Detecting Pain in Video Through Facial Action Units"}