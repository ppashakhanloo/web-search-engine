{"id": 227716500, "abstract": "This paper addresses the issue of model selection for hidden Markov models\n(HMMs). We generalize factorized asymptotic Bayesian inference (FAB), which has\nbeen recently developed for model selection on independent hidden variables\n(i.e., mixture models), for time-dependent hidden variables. As with FAB in\nmixture models, FAB for HMMs is derived as an iterative lower bound\nmaximization algorithm of a factorized information criterion (FIC). It\ninherits, from FAB for mixture models, several desirable properties for\nlearning HMMs, such as asymptotic consistency of FIC with marginal\nlog-likelihood, a shrinkage effect for hidden state selection, monotonic\nincrease of the lower FIC bound through the iterative optimization. Further, it\ndoes not have a tunable hyper-parameter, and thus its model selection process\ncan be fully automated. Experimental results shows that FAB outperforms\nstates-of-the-art variational Bayesian HMM and non-parametric Bayesian HMM in\nterms of model selection accuracy and computational efficiency.", "cluster": "4", "citations": [279309788, 272431489, 259723956, 277015912], "references": [220049264, 224175402, 220815883, 2522353, 221653506, 224881743, 34000771], "authors": ["Ryohei Fujimaki", "Kohei Hayashi"], "title": "Factorized Asymptotic Bayesian Hidden Markov Models"}