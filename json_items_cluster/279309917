{"id": 279309917, "abstract": "  Stochastic variational inference (SVI) is emerging as the most promising\ncandidate for scaling inference in Bayesian probabilistic models to large\ndatasets. However, the performance of these methods has been assessed primarily\nin the context of Bayesian topic models, particularly latent Dirichlet\nallocation (LDA). Deriving several new algorithms, and using synthetic, image\nand genomic datasets, we investigate whether the understanding gleaned from LDA\napplies in the setting of sparse latent factor models, specifically beta\nprocess factor analysis (BPFA). We demonstrate that the big picture is\nconsistent: using Gibbs sampling within SVI to maintain certain posterior\ndependencies is extremely effective. However, we find that different posterior\ndependencies are important in BPFA relative to LDA. Particularly,\napproximations able to model intra-local variable dependence perform best. ", "cluster": "0", "citations": [], "references": [259400035, 220848162, 228083473, 2239690, 228095627, 38359431, 220270203, 2433873, 243766298, 2468788], "authors": ["Amar Shah", "David A. Knowles", "Zoubin Ghahramani"], "title": "An Empirical Study of Stochastic Variational Algorithms for the Beta Bernoulli Process"}