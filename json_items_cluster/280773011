{"id": 280773011, "abstract": "In applications of Gaussian processes where quantification of uncertainty is\na strict requirement, it is necessary to accurately characterize the posterior\ndistribution over Gaussian process covariance parameters. Normally, this is\ndone by means of Markov chain Monte Carlo (MCMC) algorithms. Focusing on\nGaussian process regression where the marginal likelihood is computable but\nexpensive to evaluate, this paper studies algorithms based on importance\nsampling to carry out expectations under the posterior distribution over\ncovariance parameters. The results indicate that expectations computed using\nAdaptive Multiple Importance Sampling converge faster per unit of computation\nthan those computed with MCMC algorithms for models with few covariance\nparameters, and converge as fast as MCMC for models with up to around twenty\ncovariance parameters.", "cluster": "5", "citations": [], "references": [2836794, 271218362, 257618460, 2136938, 2762543, 38322292, 51956659, 4772045, 261198282, 4788953], "authors": ["Xiaoyu Xiong", "Václav Šmídl", "Maurizio Filippone"], "title": "Adaptive Multiple Importance Sampling for Gaussian Processes"}