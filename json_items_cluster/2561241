{"id": 2561241, "abstract": "Gaussian process regression allows a simple analytical treatment of exact Bayesian inference and has been found to provide good performance, yet scales badly with the number of training data. In this paper we compare several approaches towards scaling Gaussian processes regression to large data sets: the subset of representers method, the reduced rank approximation, online Gaussian processes, and the Bayesian committee machine. Furthermore we provide theoretical insight into some of our experimental results. We found that subset of representers methods can give good and particularly fast predictions for data sets with high and medium noise levels. On complex low noise data sets, the Bayesian committee machine achieves significantly better accuracy, yet at a higher computational cost.", "cluster": "2", "citations": [257200696, 226833116, 228530433, 246651856, 221185952, 240711266, 242367203, 242388870, 239575096, 242415837], "references": [2800860, 2535618, 49459305, 246989367, 248512895, 200524170, 221345552, 5595969, 2538204, 12218265], "authors": ["Anton Schwaighofer", "Volker Tresp"], "title": "Transductive and Inductive Methods for Approximate Gaussian Process Regression"}