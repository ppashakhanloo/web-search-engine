{"id": 274012431, "abstract": "Multi-output Gaussian processes have received increasing attention during the\nlast few years as a natural mechanism to extend the powerful flexibility of\nGaussian processes to the setup of multiple output variables. The key point\nhere is the ability to design kernel functions that allow exploiting the\ncorrelations between the outputs while fulfilling the positive definiteness\nrequisite for the covariance function. Alternatives to construct these\ncovariance functions are the linear model of coregionalization and process\nconvolutions. Each of these methods demand the specification of the number of\nlatent Gaussian process used to build the covariance function for the outputs.\nWe propose in this paper, the use of an Indian Buffet process as a way to\nperform model selection over the number of latent Gaussian processes. This type\nof model is particularly important in the context of latent force models, where\nthe latent forces are associated to physical quantities like protein profiles\nor latent forces in mechanical systems. We use variational inference to\nestimate posterior distributions over the variables involved, and show examples\nof the model performance over artificial data, a motion capture dataset, and a\ngene expression dataset.", "cluster": "0", "citations": [], "references": [45890599, 7194602, 220320048, 221617931, 220320070, 31746367, 220320085, 248512106, 225860489, 221618095], "authors": ["Cristian Guarnizo", "Mauricio A. √Ålvarez"], "title": "Indian Buffet process for model selection in convolved multiple-output Gaussian processes"}