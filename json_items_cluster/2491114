{"id": 2491114, "abstract": "I present an expectation-maximization (EM) algorithm for principal component analysis (PCA). The algorithm allows a few eigenvectors and eigenvalues to be extracted from large collections of high dimensional data. It is computationally very efficient in space and time. It also naturally accommodates missing information. I also introduce a new variant of PCA called sensible principal component analysis (SPCA) which defines a proper density model in the data space. Learning for SPCA is also done with an EM algorithm. I report results on synthetic and real data showing that these EM algorithms correctly and efficiently find the leading eigenvectors of the covariance of datasets in a few iterations using up to hundreds of thousands of datapoints in thousands of dimensions.", "cluster": "3", "citations": [263355993, 261742005, 257836555, 249644806, 236613264, 229017048, 230805155, 220057811, 221346180, 49716562], "references": [242630710, 2811474, 224881862, 4771963, 44473500, 221995817, 13338034, 2798564, 2648965, 239049889], "authors": ["Sam Roweis"], "title": "Em algorithms for pca and spca"}