{"id": 4741797, "abstract": "In recent years the Dirichlet process prior has experienced a great success in the context of Bayesian mixture modeling. The idea of overcoming discreteness of its realizations by exploiting it in hierarchical models, combined with the development of suitable sampling techniques, represent one of the reasons of its popularity. In this article we propose the normalized inverse-Gaussian (N—IG) process as an alternative to the Dirichlet process to be used in Bayesian hierarchical models. The N—IG prior is constructed via its finite-dimensional distributions. This prior, although sharing the discreteness property of the Dirichlet prior, is characterized by a more elaborate and sensible clustering which makes use of all the information contained in the data. Whereas in the Dirichlet case the mass assigned to each observation depends solely on the number of times that it occurred, for the N—IG prior the weight of a single observation depends heavily on the whole number of ties in the sample. Moreover, expressions corresponding to relevant statistical quantities, such as a priori moments and the predictive distributions, are as tractable as those arising from the Dirichlet process. This implies that well-established sampling schemes can be easily extended to cover hierarchical models based on the N—IG process. The mixture of N—IG process and the mixture of Dirichlet process are compared using two examples involving mixtures of normals.", "cluster": "4", "citations": [280104095, 266856377, 259346848, 258443836, 256199851, 258229459, 264362734, 259462942, 233753062, 228083603], "references": [24058793, 4958879, 4815760, 5106090, 4958889, 5106091, 222005302, 222569737, 222401589, 24064435], "authors": ["Antonio Lijoi", "Ramses H. Mena", "Igor Prunster"], "title": "Hierarchical Mixture Modeling With Normalized Inverse-Gaussian Priors"}