{"id": 273157807, "abstract": "We introduce a new structured kernel interpolation (SKI) framework, which\ngeneralises and unifies inducing point methods for scalable Gaussian processes\n(GPs). SKI methods produce kernel approximations for fast computations through\nkernel interpolation. The SKI framework clarifies how the quality of an\ninducing point approach depends on the number of inducing (aka interpolation)\npoints, interpolation strategy, and GP covariance kernel. SKI also provides a\nmechanism to create new scalable kernel methods, through choosing different\nkernel interpolation strategies. Using SKI, with local cubic kernel\ninterpolation, we introduce KISS-GP, which is 1) more scalable than inducing\npoint alternatives, 2) naturally enables Kronecker and Toeplitz algebra for\nsubstantial additional gains in scalability, without requiring any grid data,\nand 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n)\ntime and storage for GP inference. We evaluate KISS-GP for kernel matrix\napproximation, kernel learning, and natural sound modelling.", "cluster": "2", "citations": [277333889], "references": [234779817, 268391573, 2445967, 234831360, 238724762, 269876253, 2893638, 247598156, 221346355, 257069490], "authors": ["Andrew Gordon Wilson", "Hannes Nickisch"], "title": "Kernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP)"}