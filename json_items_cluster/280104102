{"id": 280104102, "abstract": "Consider the ordinal optimization problem of finding a population amongst\nmany with the smallest mean when these means are unknown but population samples\ncan be generated via simulation. Typically, by selecting a population with the\nsmallest sample mean, it can be shown that the false selection probability\ndecays at an exponential rate. Lately researchers have sought algorithms that\nguarantee that this probability is restricted to a small $\\delta$ in order\n$\\log(1/\\delta)$ computational time by estimating the associated large\ndeviations rate function via simulation. We show that such guarantees are\nmisleading. Enroute, we identify the large deviations principle followed by the\nempirically estimated large deviations rate function that may also be of\nindependent interest. Further, we show a negative result that when populations\nhave unbounded support, any policy that asymptotically identifies the correct\npopulation with probability at least $1-\\delta$ for each problem instance\nrequires more than $O(\\log(1/\\delta))$ samples in making such a determination\nin any problem instance. This suggests that some restrictions are essential on\npopulations to devise $O(\\log(1/\\delta))$ algorithms with $1 - \\delta$\ncorrectness guarantees. We note that under restriction on population moments,\nsuch methods are easily designed. We also observe that sequential methods from\nstochastic multi-armed bandit literature can be adapted to devise such\nalgorithms.", "cluster": "4", "citations": [], "references": [221525334, 221526561, 258727169, 225176417, 220320322, 266012427, 221529741, 261337930, 38362986, 228574100], "authors": ["Peter Glynn", "Sandeep Juneja"], "title": "Ordinal optimization - empirical large deviations rate estimators, and stochastic multi-armed bandits"}