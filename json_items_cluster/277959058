{"id": 277959058, "abstract": "We propose Kernel Hamiltonian Monte Carlo (KMC), a gradient-free adaptive\nMCMC algorithm based on Hamiltonian Monte Carlo (HMC). On target densities\nwhere classical HMC is not an option due to intractable gradients, KMC\nadaptively learns the target's gradient structure by fitting an exponential\nfamily model in a Reproducing Kernel Hilbert Space. Computational costs are\nreduced by two novel efficient approximations to this gradient. While being\nasymptotically exact, KMC mimics HMC in terms of sampling efficiency, and\noffers substantial mixing improvements over state-of-the-art gradient free\nsamplers. We support our claims with experimental studies on both toy and\nreal-world applications, including Approximate Bayesian Computation and\nexact-approximate MCMC.", "cluster": "5", "citations": [277959344], "references": [24168169, 8970227, 260232379, 271855091, 250613960, 259288193, 239382660, 221620515, 268820276, 224980705], "authors": ["Heiko Strathmann", "Dino Sejdinovic", "Samuel Livingstone", "Zoltan Szabo", "Arthur Gretton"], "title": "Gradient-free Hamiltonian Monte Carlo with Efficient Kernel Exponential Families"}