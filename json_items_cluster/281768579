{"id": 281768579, "abstract": "In convex optimization, there is an {\\em acceleration} phenomenon in which we\ncan boost the convergence rate of certain gradient-based algorithms. We can\nobserve this phenomenon in Nesterov's accelerated gradient descent, accelerated\nmirror descent, and accelerated cubic-regularized Newton's method, among\nothers. In this paper, we show that the family of higher-order gradient methods\nin discrete time (generalizing gradient descent) corresponds to a family of\nfirst-order rescaled gradient flows in continuous time. On the other hand, the\nfamily of {\\em accelerated} higher-order gradient methods (generalizing\naccelerated mirror descent) corresponds to a family of second-order\ndifferential equations in continuous time, each of which is the Euler-Lagrange\nequation of a family of Lagrangian functionals. We also study the exponential\nvariant of the Nesterov Lagrangian, which corresponds to a generalization of\nNesterov's restart scheme and achieves a linear rate of convergence in discrete\ntime. Finally, we show that the family of Lagrangians is closed under time\ndilation (an orbit under the action of speeding up time), which demonstrates\nthe universality of this Lagrangian view of acceleration in optimization.", "cluster": "3", "citations": [283658896], "references": [2433873, 280590551, 257291640, 243787569, 23948415, 225600217, 220589612, 224285355, 258114143, 273157680], "authors": ["Andre Wibisono", "Ashia C. Wilson"], "title": "On Accelerated Methods in Optimization"}