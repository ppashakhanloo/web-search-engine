{"id": 236235190, "abstract": "Can we make Bayesian posterior MCMC sampling more efficient when faced with\nvery large datasets? We argue that computing the likelihood for N datapoints\ntwice in order to reach a single binary decision is computationally\ninefficient. We introduce an approximate Metropolis-Hastings rule based on a\nsequential hypothesis test which allows us to accept or reject samples with\nhigh confidence using only a fraction of the data required for the exact MH\nrule. While this introduces an asymptotic bias, we show that this bias can be\ncontrolled and is more than offset by a decrease in variance due to our ability\nto draw more samples per unit of time. We show that the same idea can also be\napplied to Gibbs sampling in densely connected graphs.", "cluster": "5", "citations": [281262237, 281058916, 280589611, 280033955, 278733347, 264936676, 273640222, 273157850, 269722347, 269692923], "references": [1993692, 200105001, 2670104, 270443185, 30975436, 31403274, 221346425, 24168169, 19595229, 216633469], "authors": ["Anoop Korattikara", "Yutian Chen", "Max Welling"], "title": "Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget"}