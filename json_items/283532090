{"references": [220343859, 277333816, 41781721, 272194743, 2899274, 269935079, 259400035, 263316327, 269721958, 272194892], "title": "The Variational Fair Auto Encoder", "abstract": "We investigate the problem of learning representations that are invariant to\ncertain nuisance or sensitive factors of variation in the data while retaining\nas much of the remaining information as possible. Our model is based on a\nvariational auto-encoding architecture with priors that encourage independence\nbetween sensitive and latent factors of variation. Any subsequent processing,\nsuch as classification, can then be performed on this purged latent\nrepresentation. To remove any remaining dependencies we incorporate an\nadditional penalty term based on the ``Maximum Mean Discrepancy'' (MMD)\nmeasure. We discuss how these architectures can be efficiently trained on data\nand show in experiments that this method is more effective than previous work\nin removing unwanted sources of variation while maintaining informative latent\nrepresentations.", "authors": ["Christos Louizos", "Kevin Swersky", "Yujia Li", "Max Welling", "Richard Zemel"], "citations": [284219429, 284097267], "id": 283532090}