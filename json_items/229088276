{"references": [2538294, 32896369, 221345210, 221012856, 3192590, 220873154, 221012920, 220017637, 221013080, 228379274], "title": "Exact Sampling and Decoding in High-Order Hidden Markov Models", "abstract": "We present a method for exact optimization and sampling from high order Hidden Markov Models (HMMs), which are generally handled by approximation techniques. Motivated by adaptive rejection sampling and heuristic search, we propose a strategy based on sequentially refining a lower-order language model that is an upper bound on the true model we wish to decode and sample from. This allows us to build tractable variable-order HMMs. The ARPA format for language models is extended to enable an efficient use of the max-backoff quantities required to compute the upper bound. We evaluate our approach on two problems: a SMS-retrieval task and a POS tagging experiment using 5-gram models. Results show that the same approach can be used for exact optimization and sampling, while explicitly constructing only a fraction of the total implicit state-space.", "authors": ["Simon Carter", "Marc Dymetman", "Guillaume Bouchard"], "citations": [228103017], "id": 229088276}