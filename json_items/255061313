{"references": [33020867, 34000771, 226832967, 3032582, 3084564, 220695762, 221995817, 2425869, 246784707, 226435002], "title": "Two problems with variational expectation maximisation for time-series models", "abstract": "Variational methods are a key component of the approximate inference and learn- ing toolbox. These methods fill an important middle ground, r etaining distribu- tional information about uncertainty in latent variables, unlike maximum a pos- teriori methods (MAP), and yet requiring fewer computational resources than Monte Carlo Markov Chain methods. In particular the variational Expectation Maximisation (vEM) and variational Bayes algorithms, both involving variational optimisation of a free energy, are widely used in time-serie s modelling. Here, we investigate the success of vEM in simple probabilistic time-series models. First we consider the inference step of vEM, and show that a consequence of the well- known compactness property is a failure to propagate uncertainty in time, thus limiting the usefulness of the retained distributional inf ormation. In particular, the uncertainty may appear to be smallest precisely when the approximation is poor- est. Second, we consider parameter learning and analytical ly reveal systematic biases in the parameters found by vEM. Surprisingly, simpler variational approxi- mations (such a mean-field) can lead to less bias than more com plicated structured approximations.", "authors": ["Richard E. Turner", "Pietro Berkes", "Maneesh Sahani"], "citations": [286513408, 278332201, 267454297, 228083473, 221860718, 268370482, 26789821, 262273215, 261303570, 256926306], "id": 255061313}