{"references": [220320201, 220320714, 2491402, 2281698, 38003080, 40498273, 49459301, 221619935, 221345535, 3835557], "title": "Bayesian Gaussian Process Latent Variable Model.", "abstract": "We introduce a variational inference framework for training the Gaussian process latent variable model and thus performing Bayesian nonlinear dimensionality reduction. This method allows us to variationally integrate out the input vari- ables of the Gaussian process and compute a lower bound on the exact marginal likelihood of the nonlinear latent variable model. The maxi- mization of the variational lower bound provides a Bayesian training procedure that is robust to overfitting and can automatically select the di- mensionality of the nonlinear latent space. We demonstrate our method on real world datasets. The focus in this paper is on dimensionality re- duction problems, but the methodology is more general. For example, our algorithm is imme- diately applicable for training Gaussian process models in the presence of missing or uncertain inputs.", "authors": ["Michalis K. Titsias", "Neil D. Lawrence"], "citations": [279633240, 267393284, 275588150, 283296491, 267157313, 262840808, 262808718, 260089482, 263858663, 259637877], "id": 220320635}