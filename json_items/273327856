{"references": [221346425, 45630121, 236653886, 259584383, 269692923, 228926940], "title": "Hamiltonian ABC", "abstract": "Approximate Bayesian computation (ABC) is a powerful and elegant framework\nfor performing inference in simulation-based models. However, due to the\ndifficulty in scaling likelihood estimates, ABC remains useful for relatively\nlow-dimensional problems. We introduce Hamiltonian ABC (HABC), a set of\nlikelihood-free algorithms that apply recent advances in scaling Bayesian\nlearning using Hamiltonian Monte Carlo (HMC) and stochastic gradients. We find\nthat a small number forward simulations can effectively approximate the ABC\ngradient, allowing Hamiltonian dynamics to efficiently traverse parameter\nspaces. We also describe a new simple yet general approach of incorporating\nrandom seeds into the state of the Markov chain, further reducing the random\nwalk behavior of HABC. We demonstrate HABC on several typical ABC problems, and\nshow that HABC samples comparably to regular Bayesian inference using true\ngradients on a high-dimensional problem from machine learning.", "authors": ["Edward Meeds", "Robert Leenders", "Max Welling"], "citations": [], "id": 273327856}