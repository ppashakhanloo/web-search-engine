{"references": [253641345, 267157313, 221140644, 232805135, 51918516, 227716408, 221719662, 263812910, 221040266, 260089482], "title": "Semi-described and semi-supervised learning with Gaussian processes", "abstract": "Propagating input uncertainty through non-linear Gaussian process (GP)\nmappings is intractable. This hinders the task of training GPs using uncertain\nand partially observed inputs. In this paper we refer to this task as\n\"semi-described learning\". We then introduce a GP framework that solves both,\nthe semi-described and the semi-supervised learning problems (where missing\nvalues occur in the outputs). Auto-regressive state space simulation is also\nrecognised as a special case of semi-described learning. To achieve our goal we\ndevelop variational methods for handling semi-described inputs in GPs, and\ncouple them with algorithms that allow for imputing the missing values while\ntreating the uncertainty in a principled, Bayesian manner. Extensive\nexperiments on simulated and real-world data study the problems of iterative\nforecasting and regression/classification with missing values. The results\nsuggest that the principled propagation of uncertainty stemming from our\nframework can significantly improve performance in these tasks.", "authors": ["Andreas Damianou", "Neil D. Lawrence"], "citations": [284476380, 284476202], "id": 281486855}