{"references": [228092206, 228083473, 259528495, 200744767, 220320926, 3080172, 220442791, 246554763, 221346060, 279808509], "title": "Kullback-Leibler Proximal Variational Inference", "abstract": "We propose a new variational inference method based on the Kullback-Leibler (KL) proximal term. We make two contributions towards improving efficiency of variational inference. Firstly, we derive a KL proximal-point algorithm and show its equivalence to gradient descent with natural gradient in stochastic variational inference. Secondly, we use the proximal framework to derive efficient variational algorithms for non-conjugate models. We propose a splitting procedure to separate non-conjugate terms from conjugate ones. We then linearize the non-conjugate terms and show that the resulting subproblem admits a closed-form solution. Overall, our approach converts a non-conjugate model to subproblems that involve inference in well-known conjugate models. We apply our method to many models and derive generalizations for non-conjugate exponential family. Applications to real-world datasets show that our proposed algorithms are easy to implement, fast to converge, perform well, and reduce computations.", "authors": ["Mohammad Emtiyaz Khan", "Pierre Bruno Baqu√©", "Francois Fleuret", "Pascal Fua"], "citations": [], "id": 287209198}