{"references": [283761858, 283296556, 278775039, 220320835, 225237917, 2985446, 267375494, 41781188, 225307589, 257410088], "title": "Variational Auto-encoded Deep Gaussian Processes", "abstract": "We develop a scalable deep non-parametric generative model by augmenting deep\nGaussian processes with a recognition model. Inference is performed in a novel\nscalable variational framework where the variational posterior distributions\nare reparametrized through a multilayer perceptron. The key aspect of this\nreformulation is that it prevents the proliferation of variational parameters\nwhich otherwise grow linearly in proportion to the sample size. We derive a new\nformulation of the variational lower bound that allows us to distribute most of\nthe computation in a way that enables to handle datasets of the size of\nmainstream deep learning tasks. We show the efficacy of the method on a variety\nof challenges including deep unsupervised learning and deep Bayesian\noptimization.", "authors": ["Zhenwen Dai", "Andreas Damianou", "Javier Gonz√°lez", "Neil Lawrence"], "citations": [], "id": 284476380}