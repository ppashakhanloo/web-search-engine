{"references": [220616937, 239292007, 3023642, 220343796, 2265004, 221499155, 239064206, 244955528, 265459088, 225176417], "title": "Lower Bounds on the Sample Complexity of Exploration in the Multi-armed Bandit Problem", "abstract": "We consider the Multi-armed bandit problem under the PAC (\"probably approximately correct\") model. It was shown by Even-Dar et al. (5) that given n arms, it suces to play the arms a total of O (n=\"2)log(1=-) times to find an \"-optimal arm with probability of at least 1ยก-. Our contribution is a matching lower bound that holds for any sampling policy. We also generalize the lower bound to a Bayesian setting, and to the case where the statistics of the arms are known but the identities of the arms are not.", "authors": ["Shie Mannor", "John N. Tsitsiklis"], "citations": [275587982, 273067644, 263545276, 262452441, 230802961, 254056798, 221706417, 221664696, 235683564, 235683569], "id": 221497401}