{"references": [200622065, 38322438, 2113732, 2834582, 31403274, 227425151, 225635105, 257620188, 222699567, 227672958], "title": "Optimal scaling for the transient phase of Metropolis Hastings algorithms: The longtime behavior", "abstract": "We consider the Random Walk Metropolis algorithm on $\\R^n$ with Gaussian\nproposals, and when the target probability measure is the $n$-fold product of a\none dimensional law. It is well-known (see Roberts et al. (1997))) that, in the\nlimit $n \\to \\infty$, starting at equilibrium and for an appropriate scaling of\nthe variance and of the timescale as a function of the dimension $n$, a\ndiffusive limit is obtained for each component of the Markov chain. In Jourdain\net al. (2012), we generalize this result when the initial distribution is not\nthe target probability measure. The obtained diffusive limit is the solution to\na stochastic differential equation nonlinear in the sense of McKean. In the\npresent paper, we prove convergence to equilibrium for this equation. We\ndiscuss practical counterparts in order to optimize the variance of the\nproposal distribution to accelerate convergence to equilibrium. Our analysis\nconfirms the interest of the constant acceptance rate strategy (with acceptance\nrate between 1/4 and 1/3) first suggested in Roberts et al. (1997). We also\naddress scaling of the Metropolis-Adjusted Langevin Algorithm. When starting at\nequilibrium, a diffusive limit for an optimal scaling of the variance is\nobtained in Roberts and Rosenthal (1998). In the transient case, we obtain\nformally that the optimal variance scales very differently in $n$ depending on\nthe sign of a moment of the distribution, which vanishes at equilibrium. This\nsuggest that it is difficult to derive practical recommendations for MALA from\nsuch asymptotic results.", "authors": ["Benjamin Jourdain", "Tony Lelièvre", "Błażej Miasojedow"], "citations": [232718818, 262489444, 279062934], "id": 233967527}