{"references": [253641345, 267157313, 221140644, 232805135, 51918516, 227716408, 221719662, 263812910, 221040266, 260089482], "title": "Semi-described and semi-supervised learning with Gaussian processes", "abstract": "Propagating input uncertainty through non-linear Gaussian process (GP) mappings is intractable. This hinders the task of training GPs using uncertain and partially observed inputs. In this paper we refer to this task as \" semi-described learning \". We then introduce a GP framework that solves both, the semi-described and the semi-supervised learning problems (where missing values occur in the outputs). Auto-regressive state space simulation is also recognised as a special case of semi-described learning. To achieve our goal we develop variational methods for handling semi-described inputs in GPs, and couple them with algorithms that allow for imputing the missing values while treating the uncertainty in a principled, Bayesian manner. Extensive experiments on simulated and real-world data study the problems of iterative forecasting and regres-sion/classification with missing values. The results suggest that the principled propagation of uncertainty stemming from our framework can significantly improve performance in these tasks.", "authors": ["Andreas Damianou", "Neil D Lawrence"], "citations": [], "id": 283296484}