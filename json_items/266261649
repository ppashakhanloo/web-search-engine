{"references": [221618837, 265434703, 224335433, 38357862, 3479904, 254212736, 221996674, 220286556, 2893638, 226088660], "title": "Adaptive Low-Complexity Sequential Inference for Dirichlet Process Mixture Models", "abstract": "We develop a sequential low-complexity inference procedure for Dirichlet process mixtures of Gaussians for online clustering and parameter estimation when the number of clusters are unknown a-priori. We present an easily computable, closed form parametric expression for the conditional likelihood, in which hyperparameters are recursively updated as a function of the streaming data assuming conjugate priors. Motivated by large-sample asymptotics, we propose a novel adaptive low-complexity design for the Dirichlet process concentration parameter and show that the number of classes grow at most at a logarithmic rate. We further prove that in the large-sample limit, the conditional likelihood and data predictive distribution become asymptotically Gaussian. We demonstrate through experiments on synthetic and real data sets that our approach is superior to other online state-of-the-art methods.", "authors": ["Theodoros Tsiligkaridis", "Keith W. Forsythe"], "citations": [280491673], "id": 266261649}